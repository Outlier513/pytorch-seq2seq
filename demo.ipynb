{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import spacy\n",
    "import random\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data import get_tokenizer, to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_de = get_tokenizer('spacy','de_core_news_sm')\n",
    "tokenizer_en = get_tokenizer('spacy','en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = Multi30k(root='data')\n",
    "train_dataset = to_map_style_dataset(train_dataset)\n",
    "val_dataset = to_map_style_dataset(val_dataset)\n",
    "test_dataset = to_map_style_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29000, 1014, 1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yiled_token(dataset, tokenizer):\n",
    "    index = 0 if type(tokenizer.keywords['spacy']) == spacy.lang.de.German else 1\n",
    "    for items in dataset:\n",
    "        yield tokenizer(items[index].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_de = build_vocab_from_iterator(yiled_token(train_dataset, tokenizer_de), min_freq=2, specials=['<pad>','<unk>','<bos>','<eos>'])\n",
    "vocab_en = build_vocab_from_iterator(yiled_token(train_dataset, tokenizer_en), min_freq=2, specials=['<pad>','<unk>','<bos>','<eos>'])\n",
    "vocab_de.set_default_index(1)\n",
    "vocab_en.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform2token(dataset):\n",
    "    length = len(dataset)\n",
    "    for i in range(length):\n",
    "        src, trg = dataset._data[i]\n",
    "        src = tokenizer_de(src)\n",
    "        trg = tokenizer_en(trg)\n",
    "        src = [vocab_de['<bos>']] + [vocab_de[x.lower()] for x in src] + [vocab_de['<eos>']]\n",
    "        trg = [vocab_en['<bos>']] + [vocab_en[x.lower()] for x in trg] + [vocab_en['<eos>']]\n",
    "        dataset._data[i] = (torch.LongTensor(src), torch.LongTensor(trg))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7853, 5893)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_de),len(vocab_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = transform2token(train_dataset)\n",
    "val_dataset = transform2token(val_dataset)\n",
    "test_dataset = transform2token(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    src_list, trg_list = [], []\n",
    "    for src, trg in batch:\n",
    "        src_list.append(src)\n",
    "        trg_list.append(trg)\n",
    "    return pad_sequence(src_list), pad_sequence(trg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sample(dataset, batch_size):\n",
    "    indices = [(i, len(s[0])) for i, s in enumerate(dataset)]\n",
    "    random.shuffle(indices)\n",
    "    pooled_indices = []\n",
    "    for i in range(0, len(indices), batch_size*100):\n",
    "        pooled_indices.extend(sorted(indices[i:i + batch_size * 100], key=lambda x: x[1]))\n",
    "    pooled_indices = [x[0] for x in pooled_indices]\n",
    "    for i in range(0, len(pooled_indices), batch_size):\n",
    "        yield pooled_indices[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_sampler=batch_sample(train_dataset, batch_size),collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,    2,    2,    2,    2,    2,    2,    2],\n",
      "        [   5,    5,    8,    5,    5,    5,    5,    5],\n",
      "        [   1,   66,   16,   13,    1,   13,   13, 4906],\n",
      "        [ 116,   25,  159,    7, 2010,   12,   29,   66],\n",
      "        [  60,    7,   21,    6,   23,    6,    7,   25],\n",
      "        [  21,    6,   75,   82,   39,   87,   15,   11],\n",
      "        [   6,  102,   10,   79,  207,   62,  436, 1984],\n",
      "        [1282,   40,   93,  404,    9,   21,  151,   31],\n",
      "        [   7,   37, 5977,    8,   64,   14, 1114,   12],\n",
      "        [   6,    8,    7,  916,  139,  747,    7,   33],\n",
      "        [3877,  168,   15,   10,    1,   46,   77,  779],\n",
      "        [ 117,    1,   81,    5,   28,  556,  112,   44],\n",
      "        [   4,    4,    4,  587,  756,  117,  194,  395],\n",
      "        [   3,    3,    3,    4,    4,    4,    4,    4],\n",
      "        [   0,    0,    0,    3,    3,    3,    3,    3]])\n",
      "torch.Size([15, 8])\n",
      "tensor([[   2,    2,    2,    2,    2,    2,    2,    2],\n",
      "        [  21,    4,    4,    4,    4,    4,    4,    4],\n",
      "        [ 937,   53,   14,    9,  192,    9,    9, 2001],\n",
      "        [ 154,   33,  465,    6, 1552,    8,   89,  867],\n",
      "        [ 125,    6,    4,    4,  489,    4,    6, 1714],\n",
      "        [  49,    4,  875,   52,   27,  157,   27,   53],\n",
      "        [   4,   62,   13,   23,    1,  241,   70,   33],\n",
      "        [1230,   23, 4473,  304,   49,  232,  180,   32],\n",
      "        [   6,   45,    6,    4,  321,    4,    6,    8],\n",
      "        [   4,    4,  139,  596,   27,  278,    7,    4],\n",
      "        [1333,  289,    5,   11,  158,   29,  168,    9],\n",
      "        [  12, 5646,    3,  413,    5,  532,   12,  102],\n",
      "        [ 511,    5,    0,    5,    3,    5,    7,  876],\n",
      "        [   5,    3,    0,    3,    0,    3,  318,    5],\n",
      "        [   3,    0,    0,    0,    0,    0,    5,    3],\n",
      "        [   0,    0,    0,    0,    0,    0,    3,    0]])\n",
      "torch.Size([16, 8])\n"
     ]
    }
   ],
   "source": [
    "for src, trg in train_dataloader:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
